{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for NIST database lowercase characters\n",
    "    - Model with the roposed architecture over the lowercase characters of NIST database\n",
    "    - Use hsf_4 as test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import cv2\n",
    "\n",
    "from scipy.misc import imresize, imrotate, imsave \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'              # use grayscale output color heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n"
     ]
    }
   ],
   "source": [
    "#Read NIST dataset \n",
    "\n",
    "#Read NIST database\n",
    "path_NIST='/home/jorge/data/tesis/handwriting/databases/NIST/by_class/'\n",
    "\n",
    "\n",
    "char_list_lo = ['61','62','63','64','65','66','67','68','69','6a','6b','6c','6d'\n",
    "               ,'6e','6f','70','71','72','73','74','75','76','77','78','79','7a']\n",
    "\n",
    "\n",
    "decode_lo={}\n",
    "encode_lo={}\n",
    "for i , c in enumerate(char_list_lo):\n",
    "    char = str(unichr(int(c,16)))\n",
    "    decode_lo[i] = char\n",
    "    encode_lo[char] = i\n",
    "print decode_lo              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generator of list of files in a folder and subfolders\n",
    "import os\n",
    "import shutil\n",
    "import fnmatch\n",
    "\n",
    "def gen_find(filepat,top):\n",
    "    for path, dirlist, filelist in os.walk(top):\n",
    "        for name in fnmatch.filter(filelist,filepat):\n",
    "            yield os.path.join(path,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178998, 64, 64)\n",
      "(178998,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Read train dataset\n",
    "X_trn=[]\n",
    "y_trn=[]\n",
    "for char in char_list_lo:\n",
    "    letter = str(unichr(int(char,16)))\n",
    "    images_list = gen_find(\"*.png\", path_NIST+char+'/train_'+char) \n",
    "    for img_name in images_list:\n",
    "        img = plt.imread(img_name)\n",
    "        \n",
    "        #Transform\n",
    "        img = img[32:96,32:96,0]\n",
    "        \n",
    "        X_trn += [img]\n",
    "        y_trn += [encode_lo[letter]]\n",
    "\n",
    "X_trn = 1. - np.array(X_trn)\n",
    "y_trn = np.array(y_trn)\n",
    "        \n",
    "print(X_trn.shape)\n",
    "print(y_trn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000, 64, 64)\n",
      "(12000,)\n"
     ]
    }
   ],
   "source": [
    "hsf='/hsf_4/'\n",
    "\n",
    "#Read test dataset\n",
    "X_tst=[]\n",
    "y_tst=[]\n",
    "for char in char_list_lo:\n",
    "    letter = str(unichr(int(char,16)))\n",
    "    images_list = gen_find(\"*.png\", path_NIST+char+hsf) \n",
    "    for img_name in images_list:\n",
    "        img = plt.imread(img_name)\n",
    "        \n",
    "        #Transform\n",
    "        img = img[32:96,32:96,0]\n",
    "        \n",
    "        X_tst += [img]\n",
    "        y_tst += [encode_lo[letter]]\n",
    "\n",
    "X_tst = 1. - np.array(X_tst)\n",
    "y_tst = np.array(y_tst)\n",
    "        \n",
    "print(X_tst.shape)\n",
    "print(y_tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trn = X_trn.reshape((X_trn.shape[0],1,64,64))\n",
    "X_tst = X_tst.reshape((X_tst.shape[0],1,64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN Black (CNMeM is disabled, cuDNN 5103)\n",
      "/usr/local/lib/python2.7/dist-packages/theano/sandbox/cuda/__init__.py:599: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model 1...\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "#first model\n",
    "#\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Convolution2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "print('Build model 1...')\n",
    "input_images = Input(shape=(1, 64, 64))\n",
    "\n",
    "c11 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(input_images)\n",
    "c12 = Convolution2D(64, 3, 3, border_mode='same', activation='relu')(c11)\n",
    "c1_mp = MaxPooling2D((2, 2))(c12)\n",
    "\n",
    "c21 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(c1_mp)\n",
    "c22 = Convolution2D(128, 3, 3, border_mode='same', activation='relu')(c21)\n",
    "c2_mp = MaxPooling2D((2, 2))(c22)\n",
    "\n",
    "c31 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c2_mp)\n",
    "c32 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c31)\n",
    "c33 = Convolution2D(256, 3, 3, border_mode='same', activation='relu')(c32)\n",
    "c3_mp = MaxPooling2D((2, 2))(c33)\n",
    "\n",
    "conv_out = Flatten()(c3_mp)\n",
    "\n",
    "dense1 = Dense(1024, activation='relu')(conv_out)\n",
    "after_dp1 = Dropout(0.5)(dense1)\n",
    "\n",
    "dense2 = Dense(1024, activation='relu')(after_dp1)\n",
    "after_dp2 = Dropout(0.5)(dense2)\n",
    "\n",
    "output = Dense(26, activation='softmax')(after_dp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Data augmentation in keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = 15,       # 15º of random rotation\n",
    "    width_shift_range = 0.20,  # 20% of random translation width\n",
    "    height_shift_range = 0.20, # 20% of random translation height\n",
    "    shear_range = 0.15,        # 5º of shear\n",
    "    zoom_range = 0.20)         # +- 20% of zoom \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.4641 - acc: 0.8621 - val_loss: 0.3806 - val_acc: 0.8698\n",
      "Epoch 2/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.3170 - acc: 0.9063 - val_loss: 0.3296 - val_acc: 0.8887\n",
      "Epoch 3/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2821 - acc: 0.9166 - val_loss: 0.3079 - val_acc: 0.8917\n",
      "Epoch 4/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2606 - acc: 0.9229 - val_loss: 0.3032 - val_acc: 0.8928\n",
      "Epoch 5/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2480 - acc: 0.9264 - val_loss: 0.2996 - val_acc: 0.8939\n",
      "Epoch 6/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2393 - acc: 0.9291 - val_loss: 0.2815 - val_acc: 0.8968\n",
      "Epoch 7/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2338 - acc: 0.9306 - val_loss: 0.2825 - val_acc: 0.8975\n",
      "Epoch 8/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2266 - acc: 0.9325 - val_loss: 0.2867 - val_acc: 0.8964\n",
      "Epoch 9/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2222 - acc: 0.9336 - val_loss: 0.2890 - val_acc: 0.8979\n",
      "Epoch 10/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2213 - acc: 0.9334 - val_loss: 0.2874 - val_acc: 0.8972\n",
      "Epoch 11/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2170 - acc: 0.9349 - val_loss: 0.2776 - val_acc: 0.9012\n",
      "Epoch 12/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2136 - acc: 0.9362 - val_loss: 0.2698 - val_acc: 0.9004\n",
      "Epoch 13/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2115 - acc: 0.9372 - val_loss: 0.2761 - val_acc: 0.9002\n",
      "Epoch 14/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2093 - acc: 0.9373 - val_loss: 0.2736 - val_acc: 0.9005\n",
      "Epoch 15/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2098 - acc: 0.9378 - val_loss: 0.2717 - val_acc: 0.9006\n",
      "Epoch 16/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2050 - acc: 0.9390 - val_loss: 0.2745 - val_acc: 0.8998\n",
      "Epoch 17/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2063 - acc: 0.9382 - val_loss: 0.2786 - val_acc: 0.9000\n",
      "Epoch 18/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2038 - acc: 0.9389 - val_loss: 0.2680 - val_acc: 0.9022\n",
      "Epoch 19/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2019 - acc: 0.9393 - val_loss: 0.2640 - val_acc: 0.9032\n",
      "Epoch 20/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.2025 - acc: 0.9395 - val_loss: 0.2657 - val_acc: 0.9017\n",
      "Epoch 21/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.2000 - acc: 0.9405 - val_loss: 0.2694 - val_acc: 0.9008\n",
      "Epoch 22/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.1990 - acc: 0.9405 - val_loss: 0.2643 - val_acc: 0.9032\n",
      "Epoch 23/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.1991 - acc: 0.9395 - val_loss: 0.2693 - val_acc: 0.9024\n",
      "Epoch 24/50\n",
      "178998/178998 [==============================] - 618s - loss: 0.1974 - acc: 0.9408 - val_loss: 0.2613 - val_acc: 0.9049\n",
      "Epoch 25/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1977 - acc: 0.9405 - val_loss: 0.2687 - val_acc: 0.9029\n",
      "Epoch 26/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1967 - acc: 0.9416 - val_loss: 0.2654 - val_acc: 0.9021\n",
      "Epoch 27/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1957 - acc: 0.9411 - val_loss: 0.2707 - val_acc: 0.9020\n",
      "Epoch 28/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1956 - acc: 0.9411 - val_loss: 0.2644 - val_acc: 0.9032\n",
      "Epoch 29/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1933 - acc: 0.9421 - val_loss: 0.2657 - val_acc: 0.9028\n",
      "Epoch 30/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1882 - acc: 0.9436 - val_loss: 0.2600 - val_acc: 0.9048\n",
      "Epoch 38/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1881 - acc: 0.9432 - val_loss: 0.2692 - val_acc: 0.9021\n",
      "Epoch 39/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1868 - acc: 0.9437 - val_loss: 0.2620 - val_acc: 0.9062\n",
      "Epoch 40/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1874 - acc: 0.9438 - val_loss: 0.2625 - val_acc: 0.9042\n",
      "Epoch 41/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1876 - acc: 0.9441 - val_loss: 0.2654 - val_acc: 0.9048\n",
      "Epoch 42/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1872 - acc: 0.9439 - val_loss: 0.2643 - val_acc: 0.9041\n",
      "Epoch 43/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1860 - acc: 0.9437 - val_loss: 0.2640 - val_acc: 0.9042\n",
      "Epoch 44/50\n",
      "178998/178998 [==============================] - 617s - loss: 0.1862 - acc: 0.9436 - val_loss: 0.2656 - val_acc: 0.9037\n",
      "Epoch 45/50\n",
      " 46592/178998 [======>.......................] - ETA: 447s - loss: 0.1873 - acc: 0.9434"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-67e35bd43ba1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m hist_l_1 = model_l.fit_generator(datagen.flow(X_trn, y_trn, batch_size=128),\n\u001b[0;32m      9\u001b[0m                     \u001b[0msamples_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_trn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m                     validation_data=(X_tst, y_tst))\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;32mprint\u001b[0m \u001b[1;34m'Done!'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, samples_per_epoch, nb_epoch, verbose, callbacks, validation_data, nb_val_samples, class_weight, max_q_size, nb_worker, pickle_safe)\u001b[0m\n\u001b[0;32m   1443\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   1444\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1445\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   1446\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1447\u001b[0m                     \u001b[0m_stop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1221\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1222\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1223\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1224\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1225\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/keras/backend/theano_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    529\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 530\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create the model\n",
    "model_l = Model(input=input_images, output=output)\n",
    "\n",
    "#Fit model  on batches with real-time data augmentation:\n",
    "sgd = SGD(lr=0.01, decay=0.001, momentum=0.9, nesterov=True)\n",
    "model_l.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "\n",
    "hist_l_1 = model_l.fit_generator(datagen.flow(X_trn, y_trn, batch_size=128),\n",
    "                    samples_per_epoch=len(X_trn), nb_epoch=50, \n",
    "                    validation_data=(X_tst, y_tst))\n",
    "\n",
    "print 'Done!'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy for NIST database (2nd ed) lower case: 90,4%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Save model\n",
    "path_models = '/home/jorge/data/tesis/handwriting/p01_read_character/'\n",
    "\n",
    "model_name = 'nist_lowercase_01'\n",
    "\n",
    "json_string = model_l.to_json()\n",
    "open(path_models + 'models/mdl_' + model_name + '.json', 'w').write(json_string)\n",
    "model_l.save_weights(path_models + 'models/w_' + model_name + '.h5', overwrite=True)\n",
    "\n",
    "# Save decode_target\n",
    "#import pickle\n",
    "#pickle.dump( decode_target_l, open( path_models + \"models/unipen_decode_target_lowercase.p\", \"wb\" ) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
